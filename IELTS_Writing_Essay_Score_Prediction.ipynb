{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAfesnfMB_sH"
   },
   "source": [
    "# INSTALL LIBRARIES & IMPORT DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ALjFn4G78hS",
    "outputId": "a2bcff5e-5655-48a8-a88b-0e04620274ed"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def install_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"{package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        !pip install {package_name}\n",
    "\n",
    "install_package(\"textstat\")\n",
    "install_package(\"langdetect\")\n",
    "install_package('pyspellchecker')\n",
    "install_package(\"scikeras\")\n",
    "install_package(\"transformers\")\n",
    "install_package('tensorflow_hub')\n",
    "install_package('tensorflow_text')\n",
    "install_package('wget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4FxCeon7tcs"
   },
   "outputs": [],
   "source": [
    "# Import Data Handling Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Natural Language Processing Libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Import Text Analysis and Preprocessing Libraries\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import textstat\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Import Machine Learning and Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, GRU, Flatten, Dense,\n",
    "    BatchNormalization, Dropout, Concatenate, Lambda, Bidirectional\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "# Import Machine Learning Libraries for Text Processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "\n",
    "import os\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPLgVHH9CE6h"
   },
   "source": [
    "# IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuTBpANs82oV"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/andrealolli13/Text-Mining-and-Natural-Language-Processing/main/ielts_writing_dataset.csv')\n",
    "# DATASET: IELTS Writing Scored Essays Dataset\n",
    "# LINK: https://www.kaggle.com/datasets/mazlumi/ielts-writing-scored-essays-dataset\n",
    "\n",
    "# display dataset\n",
    "print('IELTS Writing Scored Essays Dataset:\\n')\n",
    "display(data.head())\n",
    "\n",
    "# display dataset infos\n",
    "print('\\nDataset Informations:\\n')\n",
    "display(data.info())\n",
    "\n",
    "# print percentage missing values\n",
    "print('\\nPercentage Missing Values per Column:\\n')\n",
    "for col, val in (data.isna().sum().items()):\n",
    "  print(f\"Missing values in {col} = {round((val/data.shape[0])*100,2)}%\")\n",
    "\n",
    "# remove columns with missing values\n",
    "df = data.copy()\n",
    "df.drop(columns=['Examiner_Commen', 'Task_Response', 'Coherence_Cohesion', 'Lexical_Resource', 'Range_Accuracy'], inplace=True)\n",
    "\n",
    "# display new dataset\n",
    "print('\\nIELTS Writing Scored Essays Dataset NEW:\\n')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSfLS8TCFJ5V"
   },
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s38IBwXnFLUm"
   },
   "outputs": [],
   "source": [
    "# extract values\n",
    "TASK_TYPE = df.Task_Type\n",
    "QUESTIONS = df.Question\n",
    "ESSAYS = df.Essay\n",
    "OVERALL = df.Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3ISKPsxFXrQ"
   },
   "source": [
    "## CATEGORICAL DATA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUZm8rlVFeAy"
   },
   "source": [
    "### TASK TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ90SCmBFVeZ"
   },
   "outputs": [],
   "source": [
    "# occurrences of each unique value in the \"Task_Type\" column\n",
    "task_type_counts = TASK_TYPE.value_counts()\n",
    "\n",
    "# labels and sizes for the pie chart\n",
    "labels = task_type_counts.index.tolist()\n",
    "sizes = task_type_counts.values.tolist()\n",
    "colors = sns.color_palette('Blues')\n",
    "explode = (.1, 0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(sizes,labels=labels, colors=colors, autopct='%.1f %%', explode=explode, shadow=True,\n",
    "        startangle=140)\n",
    "\n",
    "plt.title('Task Type Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kySpNiMqFndk"
   },
   "source": [
    "### OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMTPnqUvFodY"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Overall', data=df, color='skyblue')\n",
    "\n",
    "plt.xlabel('OVERALL')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.title('Distribution of OVERALL Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdUqadnBHPBR"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "image_url = 'https://www.ielts.org/-/media/images/resources/cefr-ielts-300px.ashx?la=en&hash=B8E1C54B853D375FD4E4E1EF6FF8867002477A51'\n",
    "Image(url=image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88hoDsy-GLW7"
   },
   "outputs": [],
   "source": [
    "# OVERALL CONVERSION IELTS to CEFR (Common European Frameword of Refernce)\n",
    "CEFR_OVERALL = []\n",
    "\n",
    "for point in OVERALL:\n",
    "    if point >= 8.0: # C2\n",
    "        CEFR_OVERALL.append('C2')\n",
    "\n",
    "    if point >= 6.5 and point < 8.0: # C1\n",
    "        CEFR_OVERALL.append('C1')\n",
    "\n",
    "    if point >= 5.0 and point < 6.5: # B2\n",
    "        CEFR_OVERALL.append('B2')\n",
    "\n",
    "    if point >= 4.0 and point < 5.0: # B1\n",
    "        CEFR_OVERALL.append('B1')\n",
    "\n",
    "    if point < 4.0 : # BASIC (A1 or A2)\n",
    "        CEFR_OVERALL.append('A')\n",
    "\n",
    "CEFR_OVERALL = np.array(CEFR_OVERALL)\n",
    "CEFR_OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzTe-PvEGPed"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=CEFR_OVERALL, color='skyblue', order=['A', 'B1', 'B2', 'C1', 'C2'])\n",
    "\n",
    "plt.xlabel('OVERALL')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.title('Distribution of OVERALL Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChaK5WGWHhib"
   },
   "source": [
    "# NEW FEATURES (ESSAY-BASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Szb3TQqPHlcw"
   },
   "outputs": [],
   "source": [
    "# to avoid counting symbols as unique letter we are going to create a function to remove them.\n",
    "def remove_symbols(input_string):\n",
    "\n",
    "    pattern = r'[!@#$%^&*()_+{}\\[\\]:;<>,.?/~\\\\|-]'\n",
    "    cleaned_string = re.sub(pattern, ' ', input_string)\n",
    "\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKUKuiRmHrjK"
   },
   "source": [
    "## NUMBER OF MISSING WORDS TO MEET LENGTH REQUIREMENTS\n",
    "Test-takers are expected to write an essay that is at least 250 words in length.\n",
    "        Writing less than 250 words may result in a penalty to your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IWSh8VaHnUt"
   },
   "outputs": [],
   "source": [
    "MISSING_WORDS = []\n",
    "MINIMUM_WORDS = 250\n",
    "\n",
    "for essay in ESSAYS:\n",
    "\n",
    "    cleaned_essay = remove_symbols(essay)  # remove punctuation\n",
    "\n",
    "    number_of_words = len(cleaned_essay.split())\n",
    "    if number_of_words < 250:\n",
    "        number_of_missing_words = MINIMUM_WORDS - number_of_words\n",
    "    else:\n",
    "        number_of_missing_words = 0\n",
    "\n",
    "    MISSING_WORDS.append(number_of_missing_words)\n",
    "\n",
    "MISSING_WORDS = np.array(MISSING_WORDS)\n",
    "MISSING_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz_scV4PHybL"
   },
   "source": [
    "## MEAN NUMBER OF WORDS PER SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5WD7n03HyyX"
   },
   "outputs": [],
   "source": [
    "MEAN_SENTENCE_LENGTH = []\n",
    "\n",
    "for essay in ESSAYS:\n",
    "\n",
    "    sentences = essay.split('.') # divide essay by sentence\n",
    "    sentences_length = [] # store sentences length\n",
    "\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = remove_symbols(sentence) # remove punctuation\n",
    "        words = cleaned_sentence.split()\n",
    "\n",
    "        # skip unwanted white spaces counted as sentences\n",
    "        if len(words) == 0:\n",
    "            continue\n",
    "\n",
    "        sentences_length.append(len(words)) # store sentence length\n",
    "\n",
    "    # compute mean length rounded to integer\n",
    "    sentences_mean_length = int(sum(sentences_length) / len(sentences_length))\n",
    "    MEAN_SENTENCE_LENGTH.append(sentences_mean_length)\n",
    "\n",
    "MEAN_SENTENCE_LENGTH = np.array(MEAN_SENTENCE_LENGTH)\n",
    "MEAN_SENTENCE_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk94BLp9H9JT"
   },
   "source": [
    "## VOCABULARY RICHNESS\n",
    "Count how many unique words are used. (We apply the following preprocessing techniques: Lowercasing, Symbols Removal, Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a9qxvSbIJYz"
   },
   "outputs": [],
   "source": [
    "UNIQUE_WORDS = []\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for essay in ESSAYS:\n",
    "\n",
    "    lower_essay = essay.lower() # lowering\n",
    "    cleaned_essay = remove_symbols(lower_essay) # punctuation removal\n",
    "    words = cleaned_essay.split() #split\n",
    "    stemmed_words = [stemmer.stem(word) for word in words] # Stem each word in the essay\n",
    "\n",
    "    number_unique_words = len(list(set(stemmed_words)))\n",
    "    UNIQUE_WORDS.append(number_unique_words)\n",
    "\n",
    "UNIQUE_WORDS = np.array(UNIQUE_WORDS)\n",
    "UNIQUE_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ir0KZBnIMn0"
   },
   "source": [
    "## READABILITY SCORES\n",
    "**Flesch-Kincaid Grade Level:**\n",
    "<code>0.39 * (average sentence length) + 11.8 * (average syllables per word) - 15.59\n",
    "</code>\n",
    "- Assesses text readability considering sentence length and word syllables.\n",
    "- Scores are represented as U.S. school grades, with 8.0 indicating eighth-grade readability.\n",
    "- Widely used for educational materials to ensure comprehension by specific grade levels.\n",
    "- Range between: (0, 20.0)\n",
    "\n",
    "**Gunning Fog Index:**\n",
    "<code>0.4 * [(average sentence length) + (percentage of complex words)]\n",
    "</code>\n",
    "- Measures text complexity by examining sentence length and the presence of complex words (those with three or more syllables).\n",
    "- Like Flesch-Kincaid, it reports scores in U.S. school grades.\n",
    "- Especially useful for evaluating technical, legal, or scientific documents, as it focuses on vocabulary complexity alongside sentence structure.\n",
    "- Range between: (0, 20.0)\n",
    "\n",
    "\n",
    "**Key Differences:**\n",
    "- Complex Words: The primary difference is that the Gunning Fog Index explicitly considers complex words (those with three or more syllables), while the Flesch-Kincaid Grade Level does not directly account for word complexity.\n",
    "- Formulas: The formulas used for calculation are different, although they both rely on sentence length as a factor.\n",
    "- Applications: Both metrics are suitable for assessing readability, but the choice between them may depend on the specific context and the type of text being analyzed. The Gunning Fog Index may be more suitable when you want to pay particular attention to complex vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTet8QrXIRKM"
   },
   "outputs": [],
   "source": [
    "FK_GRADE_LEVEL = []\n",
    "GUNNING_FOG_INDEX = []\n",
    "\n",
    "for essay in ESSAYS:\n",
    "\n",
    "    fk_grade_level = textstat.flesch_kincaid_grade(essay) # calculate Flesch-Kincaid grade level\n",
    "\n",
    "    gunning_fog_index = textstat.gunning_fog(essay) # calculate Gunning fog index\n",
    "\n",
    "    FK_GRADE_LEVEL.append(fk_grade_level)\n",
    "    GUNNING_FOG_INDEX.append(gunning_fog_index)\n",
    "\n",
    "FK_GRADE_LEVEL = np.array(FK_GRADE_LEVEL)\n",
    "GUNNING_FOG_INDEX = np.array(GUNNING_FOG_INDEX)\n",
    "\n",
    "FK_GRADE_LEVEL, GUNNING_FOG_INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyCuaTV2IZv6"
   },
   "source": [
    "## USE OF TRANSITIONAL WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbO8XcX1Ib0p"
   },
   "outputs": [],
   "source": [
    "# Additive Transitions\n",
    "additive_transitions = ['in all honesty', 'as well as this', 'much less', 'indeed', 'nor',\n",
    "       'on the other hand', 'to tell the truth', 'to say nothing of',\n",
    "       'furthermore', 'and', 'besides this', 'in addition to this',\n",
    "       'alternatively', 'either', 'in the first place', 'actually', 'or',\n",
    "       'let alone', 'additionally', 'not only this but also that as well',\n",
    "       'too', 'as a matter of fact', 'in fact', 'moreover', 'further',\n",
    "       'not to mention this', 'what is more']\n",
    "\n",
    "# Adversative Transitions\n",
    "adversative_transitions = ['whatever happens', 'yet', 'though', 'in either case',\n",
    "       'on the other hand', 'nevertheless', 'above all', 'but',\n",
    "       'at least', 'even more', 'whichever happens', 'in contrast',\n",
    "       'but even so', 'still', 'although', 'while', 'in either event',\n",
    "       'however', 'conversely', 'either way', 'whereas']\n",
    "\n",
    "# Causal Transitions\n",
    "causal_transitions = ['in the event', 'and so', 'as a result', 'with this intention',\n",
    "       'as a consequence', 'for this reason', 'with this in mind',\n",
    "       'that being the case', 'so', 'in consequence', 'then', 'therefore',\n",
    "       'because', 'so much that', 'under those circumstances',\n",
    "       'consequently', 'hence', 'for the purpose of', 'thus',\n",
    "       'accordingly', 'on the condition', 'granting']\n",
    "\n",
    "# Sequential Transitions\n",
    "sequential_transitions = ['by the way', 'initially', 'anyhow', 'in sum', 'in the place',\n",
    "       'next', 'to conclude with', 'so', 'in short', 'subsequently',\n",
    "       'to start with', 'to change the topic', 'to begin with',\n",
    "       'afterward', 'after this', 'secondly', 'as was previously stated',\n",
    "       'before', 'as a final point', 'last but not least', 'finally',\n",
    "       'thus', 'to get back to the point', 'to resume', 'incidentally']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBEWeGT0JGWA"
   },
   "outputs": [],
   "source": [
    "ADDITIVE_TRAN = []\n",
    "ADVERSATIVE_TRAN = []\n",
    "CAUSAL_TRAN = []\n",
    "SEQUENTIAL_TRAN = []\n",
    "\n",
    "for essay in ESSAYS:\n",
    "\n",
    "    lower_essay = essay.lower()\n",
    "    cleaned_essay = remove_symbols(lower_essay)\n",
    "\n",
    "    additive_count = 0\n",
    "    adversative_count = 0\n",
    "    causal_count = 0\n",
    "    sequential_count = 0\n",
    "\n",
    "    # additive loop\n",
    "    for trans in additive_transitions:\n",
    "        if trans in cleaned_essay: additive_count +=1\n",
    "    # adversative loop\n",
    "    for trans in adversative_transitions:\n",
    "        if trans in cleaned_essay: adversative_count += 1\n",
    "    # causal_count\n",
    "    for trans in causal_transitions:\n",
    "        if trans in cleaned_essay: causal_count += 1\n",
    "    # sequential count\n",
    "    for trans in sequential_transitions:\n",
    "        if trans in cleaned_essay: sequential_count += 1\n",
    "\n",
    "    ADDITIVE_TRAN.append(additive_count)\n",
    "    ADVERSATIVE_TRAN.append(adversative_count)\n",
    "    CAUSAL_TRAN.append(causal_count)\n",
    "    SEQUENTIAL_TRAN.append(sequential_count)\n",
    "\n",
    "ADDITIVE_TRAN = np.array(ADDITIVE_TRAN)\n",
    "ADVERSATIVE_TRAN = np.array(ADVERSATIVE_TRAN)\n",
    "CAUSAL_TRAN = np.array(CAUSAL_TRAN)\n",
    "SEQUENTIAL_TRAN = np.array(SEQUENTIAL_TRAN)\n",
    "\n",
    "ADDITIVE_TRAN, ADVERSATIVE_TRAN, CAUSAL_TRAN, SEQUENTIAL_TRAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGo-xQTAJKYX"
   },
   "source": [
    "## GRAMMAR AND SPELLING ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gp55-FRfJMeY"
   },
   "outputs": [],
   "source": [
    "GRAMMAR_SPELLING_ERRORS = []\n",
    "spell_checker_gb = SpellChecker(language='en')\n",
    "\n",
    "for essay in ESSAYS:\n",
    "\n",
    "    lower_essay = essay.lower()\n",
    "    cleaned_essay = remove_symbols(lower_essay)\n",
    "    words = cleaned_essay.split()\n",
    "\n",
    "    # check for spelling errors in British English\n",
    "    misspelled_gb = spell_checker_gb.unknown(words)\n",
    "\n",
    "    errors = (len(misspelled_gb))\n",
    "    GRAMMAR_SPELLING_ERRORS.append(errors)\n",
    "\n",
    "GRAMMAR_SPELLING_ERRORS = np.array(GRAMMAR_SPELLING_ERRORS)\n",
    "GRAMMAR_SPELLING_ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6FEk1mYJTTn"
   },
   "source": [
    "# NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cy5FHTeJVaR"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Task_Type' : TASK_TYPE,\n",
    "    'Question' : QUESTIONS,\n",
    "    'Essay' : ESSAYS,\n",
    "    'Missing_Words' : MISSING_WORDS,\n",
    "    'Mean_Sentence_Length': MEAN_SENTENCE_LENGTH,\n",
    "    'Vocabulary_Richness' : UNIQUE_WORDS,\n",
    "    'FK_Grade_Level' : FK_GRADE_LEVEL,\n",
    "    'Gunning_Fog_Index' : GUNNING_FOG_INDEX,\n",
    "    'Additive_Transitions' : ADDITIVE_TRAN,\n",
    "    'Adversative_Transitions' : ADVERSATIVE_TRAN,\n",
    "    'Causal_Transitions' : CAUSAL_TRAN,\n",
    "    'Sequential_Transitions' : SEQUENTIAL_TRAN,\n",
    "    'Grammar_Spelling_Errors' : GRAMMAR_SPELLING_ERRORS,\n",
    "    'CEFR_Overall' : CEFR_OVERALL\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(data)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "605sHoLRJi6P"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNP4RTGQJmIq"
   },
   "source": [
    "## NUMERICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFtXV57GJnhc"
   },
   "outputs": [],
   "source": [
    "def standardize_array(arr):\n",
    "\n",
    "    # calculate the mean and standard deviation\n",
    "    mean = np.mean(arr)\n",
    "    std_dev = np.std(arr)\n",
    "\n",
    "    # standardize the data\n",
    "    standardized_data = (arr - mean) / std_dev\n",
    "\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DirMzy2gJpRw"
   },
   "outputs": [],
   "source": [
    "# apply standardization to floating-point type arrays\n",
    "\n",
    "STD_MISSING_WORDS=standardize_array(MISSING_WORDS) # missing Words\n",
    "\n",
    "STD_MEAN_SENTENCE_LENGTH=standardize_array(MEAN_SENTENCE_LENGTH) # sentence Length\n",
    "\n",
    "STD_UNIQUE_WORDS=standardize_array(UNIQUE_WORDS) # unique words\n",
    "\n",
    "STD_FK_GRADE_LEVEL=standardize_array(FK_GRADE_LEVEL) # Flesch-Kincaid grade level\n",
    "\n",
    "STD_GUNNING_FOG_INDEX=standardize_array(GUNNING_FOG_INDEX) # Gunning Fog index\n",
    "\n",
    "STD_GRAMMAR_SPELLING_ERRORS=standardize_array(GRAMMAR_SPELLING_ERRORS) # grammar and spelling errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stWMLSucJsjv"
   },
   "source": [
    "## TEXTUAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xr6gpsayJwtl"
   },
   "outputs": [],
   "source": [
    "# join questions and essays\n",
    "CORPUS = []\n",
    "for q,e in zip(QUESTIONS, ESSAYS):\n",
    "    CORPUS.append(q + ' ' + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1YwJOHUJ2bh"
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocessing(data):\n",
    "    preprocessed_data = []\n",
    "\n",
    "    for TEXT in data:\n",
    "        # remove special characters, punctuation marks, and numbers\n",
    "        CLEANED_TEXT = re.sub(r'[^a-zA-Z\\s]', ' ', TEXT)\n",
    "        # convert text to lowercase\n",
    "        LOWERCASE_TEXT = CLEANED_TEXT.lower()\n",
    "        # tokenize the text\n",
    "        TOKENS = word_tokenize(LOWERCASE_TEXT)\n",
    "        # remove stopwords from the list of tokens\n",
    "        FILTERED_TOKENS = [word for word in TOKENS if word not in stop_words]\n",
    "        # lemmatize each word\n",
    "        LEMMATIZED_TOKENS = [lemmatizer.lemmatize(word) for word in FILTERED_TOKENS]\n",
    "        # remove single-letter words\n",
    "        FINAL_TOKENS = [word for word in LEMMATIZED_TOKENS if len(word) > 1]\n",
    "\n",
    "        preprocessed_data.append(FINAL_TOKENS)\n",
    "\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c10YOCHfJ6Sc"
   },
   "outputs": [],
   "source": [
    "PREP_CORPUS = text_preprocessing(CORPUS)\n",
    "print(f\"BEFORE PREPROCESSING.\\n\\nCORPUS:\\n{CORPUS[0]}\")\n",
    "print(f\"\\n- - - - - - - - \\n\")\n",
    "print(f\"AFTER PREPROCESSING.\\n\\nCORPUS:\\n{PREP_CORPUS[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaVdCoYCKPuG"
   },
   "outputs": [],
   "source": [
    "# max and mean lenght of CORPUS\n",
    "MAX_LENGTH_CORPUS = max(len(c.split()) for c in CORPUS)\n",
    "MEAN_LENGTH_CORPUS = sum(len(c.split()) for c in CORPUS) / len(CORPUS)\n",
    "\n",
    "# max and mean lenght of CORPUS after\n",
    "MAX_LENGTH_PREP_CORPUS = max(len(c) for c in PREP_CORPUS)\n",
    "MENA_LENGTH_PREP_CORPUS = sum(len(c) for c in PREP_CORPUS) / len(PREP_CORPUS)\n",
    "\n",
    "# labels for the bars\n",
    "labels = ['Max Length', 'Mean Length']\n",
    "\n",
    "# values for the bars\n",
    "corpus_values = [MAX_LENGTH_CORPUS, MEAN_LENGTH_CORPUS]\n",
    "prep_corpus_values = [MAX_LENGTH_PREP_CORPUS, MENA_LENGTH_PREP_CORPUS]\n",
    "\n",
    "# x-axis positions for the bars\n",
    "x = range(len(labels))\n",
    "\n",
    "# create bar plots\n",
    "fig, ax = plt.subplots()\n",
    "bar1 = ax.bar(x, corpus_values, width = 0.35, label='CORPUS')\n",
    "bar2 = ax.bar([i + 0.35 for i in x], prep_corpus_values, width = 0.35, label='PREP_CORPUS')\n",
    "\n",
    "# add labels, title, and legend\n",
    "ax.set_xlabel('Statistics')\n",
    "ax.set_ylabel('Length')\n",
    "ax.set_title('Max and Mean Lengths of CORPUS and PREP_CORPUS')\n",
    "ax.set_xticks([i + 0.35 / 2 for i in x])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# add values on top of the bars\n",
    "for bar in bar1 + bar2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}',  # Format the value to 2 decimal places\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords='offset points',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9myNfRqWKmoP"
   },
   "outputs": [],
   "source": [
    "VOCABULARY = []\n",
    "for prep_essay in PREP_CORPUS:\n",
    "    for word in prep_essay:\n",
    "        VOCABULARY.append(word)\n",
    "\n",
    "VOCABULARY = np.array(list(set(VOCABULARY)))\n",
    "\n",
    "word_to_int = {w:i for i, w in enumerate(VOCABULARY)}\n",
    "word_to_int['<UNK>'] = 11750\n",
    "int_to_word = {i:w for w,i in word_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RItgPOlbKo3I"
   },
   "outputs": [],
   "source": [
    "# fix corpus length to 314 characters\n",
    "EQUAL_LENGTH_CORP = []\n",
    "\n",
    "for prep_essay in PREP_CORPUS:\n",
    "\n",
    "    temp = []\n",
    "    for word in prep_essay:\n",
    "        temp.append(word)\n",
    "\n",
    "    while len(temp) < 314:\n",
    "        temp.append('<UNK>')\n",
    "\n",
    "    EQUAL_LENGTH_CORP.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chdz37PxKrqA"
   },
   "source": [
    "# VECTOR REPRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfFLwyrbKwHw"
   },
   "source": [
    "## PPMI MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmR7DIPsKtaD"
   },
   "outputs": [],
   "source": [
    "def compute_ppmi_matrix(tokens, vocab=word_to_int):\n",
    "\n",
    "    # initialize a matrix to store co-occurrence counts\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # count co-occurrences of words within a certain window\n",
    "    window_size = 3\n",
    "    for sentence in tokens:\n",
    "        for i, target_word in enumerate(sentence):\n",
    "            target_idx = vocab[target_word]\n",
    "            start = max(0, i - window_size)\n",
    "            end = min(len(sentence), i + window_size + 1)\n",
    "            context_words = [sentence[j] for j in range(start, end) if j != i]\n",
    "            for context_word in context_words:\n",
    "                context_idx = vocab[context_word]\n",
    "                co_occurrence_matrix[target_idx][context_idx] += 1\n",
    "\n",
    "    # convert the co-occurrence matrix to a sparse CSR matrix for memory efficiency\n",
    "    co_occurrence_matrix = csr_matrix(co_occurrence_matrix)\n",
    "\n",
    "    # compute PPMI matrix\n",
    "    sum_rows = np.array(co_occurrence_matrix.sum(axis=1)).flatten()\n",
    "    sum_cols = np.array(co_occurrence_matrix.sum(axis=0)).flatten()\n",
    "    total_sum = sum_rows.sum()\n",
    "\n",
    "    # avoid division by zero and compute PMI\n",
    "    nonzero_rows, nonzero_cols = co_occurrence_matrix.nonzero()\n",
    "    pmi_matrix = np.zeros_like(co_occurrence_matrix.toarray(), dtype=np.float64)\n",
    "    for i, j in zip(nonzero_rows, nonzero_cols):\n",
    "        pmi = np.log((co_occurrence_matrix[i, j] * total_sum) / (sum_rows[i] * sum_cols[j]))\n",
    "        pmi_matrix[i, j] = max(pmi, 0)  # apply PPMI transformation\n",
    "\n",
    "    return pmi_matrix\n",
    "\n",
    "\n",
    "ppmi_matrix = compute_ppmi_matrix(PREP_CORPUS)\n",
    "print(ppmi_matrix)\n",
    "print(ppmi_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo23Cz_vK8pw"
   },
   "source": [
    "## TF-IDF MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVKCS2ynK-pq"
   },
   "outputs": [],
   "source": [
    "CORP = [' '.join(c) for c in PREP_CORPUS]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=None, min_df=0, max_df=1.0)\n",
    "tfidf_matrix = vectorizer.fit_transform(CORP) # Compute TF-IDF matrix\n",
    "feature_names = vectorizer.get_feature_names_out() # Get the vocabulary (unique words) as feature names\n",
    "dense_tfidf_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(dense_tfidf_matrix)\n",
    "print(dense_tfidf_matrix.shape)\n",
    "\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJQe5NENLGjR"
   },
   "outputs": [],
   "source": [
    "num_rows = dense_tfidf_matrix.shape[0]\n",
    "zeros_column = np.zeros((num_rows, 1)) # '<UNK>' token column\n",
    "# concatenate the zeros column to the existing TF-IDF matrix\n",
    "dense_tfidf_matrix_with_zeros = np.hstack((dense_tfidf_matrix, zeros_column))\n",
    "\n",
    "print(\"Updated TF-IDF Matrix Shape:\")\n",
    "print(dense_tfidf_matrix_with_zeros.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvxR4CjBL3VY"
   },
   "source": [
    "## GLOVE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELjoVguoTBKD"
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    word_embeddings = {}\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            word_embeddings[word] = vector\n",
    "\n",
    "    return word_embeddings\n",
    "\n",
    "# glove_embeddings_300d = load_glove_embeddings(\"/content/drive/MyDrive/Colab Notebooks/glove.6B.300d.txt\")\n",
    "glove_embeddings_300d = load_glove_embeddings(\"glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9iWWO91TyHM"
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(glove_embeddings, embedding_dim, vocab_size = len(word_to_int)):\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in word_to_int.items():\n",
    "        embedding_vector = glove_embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "glove_emb_300d = create_embedding_matrix(glove_embeddings_300d, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Nlg9W6HT3I4"
   },
   "source": [
    "# FINAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IqGU3PtT9aF"
   },
   "outputs": [],
   "source": [
    "CORP_TO_INT = []\n",
    "\n",
    "for _ in EQUAL_LENGTH_CORP:\n",
    "\n",
    "    integer_list = []\n",
    "    for word in _ :\n",
    "        integer_list.append(word_to_int[word])\n",
    "\n",
    "    CORP_TO_INT.append(integer_list)\n",
    "\n",
    "data = CORP_TO_INT\n",
    "\n",
    "numerical = np.concatenate(\n",
    "    (TASK_TYPE.values.reshape(1, -1), STD_MISSING_WORDS.reshape(1, -1), STD_UNIQUE_WORDS.reshape(1, -1),\n",
    "    STD_FK_GRADE_LEVEL.reshape(1, -1), STD_GUNNING_FOG_INDEX.reshape(1, -1), ADDITIVE_TRAN.reshape(1, -1),\n",
    "    ADVERSATIVE_TRAN.reshape(1, -1), CAUSAL_TRAN.reshape(1, -1), SEQUENTIAL_TRAN.reshape(1, -1),\n",
    "    STD_GRAMMAR_SPELLING_ERRORS.reshape(1, -1)))\n",
    "\n",
    "numerical = numerical.T\n",
    "print(f\"Numerical Dataset shape:{numerical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVlytr4-UAmK"
   },
   "outputs": [],
   "source": [
    "# join textual and numerical data\n",
    "for i, _ in enumerate(numerical, start = 0):\n",
    "    for value in _:\n",
    "        data[i].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WY-6hNjUC9R"
   },
   "outputs": [],
   "source": [
    "# convert label into one-hot representation\n",
    "label_encoder = LabelEncoder()\n",
    "num_classes = len(np.unique(CEFR_OVERALL))\n",
    "\n",
    "y = to_categorical(label_encoder.fit_transform(CEFR_OVERALL), num_classes)\n",
    "X = np.array(data)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__8BnilxUHjS"
   },
   "source": [
    "## TRAIN, TEST & VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLOlBEKxUN9K"
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t2MRVEJUQws"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ejl-3Q4JUSUC"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=None,input_length=None,output_shape=None, embedding_matrix=None,\n",
    "                learning_rate=10**-1, loss='categorical_crossentropy', optimizer='adam',\n",
    "                gru_1_units=15, gru_2_units=15, hid_1_units=32, hid_2_units=64,\n",
    "                gru_activation='tanh', hid_activation='relu', out_activation='softmax',\n",
    "                kernel_initializer='glorot_uniform', kernel_regularizer='l1', dropout_rate=0.1):\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    text_input = Lambda(lambda x: x[:,:315])(input_layer)\n",
    "    numerical_input = Lambda(lambda x: x[:,315:])(input_layer)\n",
    "\n",
    "    embedding = Embedding(\n",
    "        input_dim=embedding_matrix.shape[0],\n",
    "        output_dim=embedding_matrix.shape[1],\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=input_length,\n",
    "        trainable=False)(text_input)\n",
    "\n",
    "    b_lstm_1 = Bidirectional(GRU(\n",
    "        units=gru_1_units,\n",
    "        activation=gru_activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer,\n",
    "        dropout=dropout_rate,\n",
    "        return_sequences=True))(embedding)\n",
    "\n",
    "    b_lstm_2 = Bidirectional(GRU(\n",
    "        units=gru_2_units,\n",
    "        activation=gru_activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer,\n",
    "        dropout=dropout_rate,\n",
    "        return_sequences=True))(b_lstm_1)\n",
    "\n",
    "    flatten = Flatten()(b_lstm_2)\n",
    "\n",
    "    concat = Concatenate()([flatten, numerical_input])\n",
    "\n",
    "    dense_1 = Dense(\n",
    "        units=hid_1_units,\n",
    "        activation=hid_activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer)(concat)\n",
    "\n",
    "    bn_1 = BatchNormalization()(dense_1)\n",
    "    dropout_1 = Dropout(dropout_rate)(bn_1)\n",
    "\n",
    "    dense_2 = Dense(\n",
    "        units=hid_2_units,\n",
    "        activation=hid_activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer)(dropout_1)\n",
    "\n",
    "    bn_2 = BatchNormalization()(dense_2)\n",
    "    dropout_2 = Dropout(dropout_rate)(bn_2)\n",
    "\n",
    "    output_layer = Dense(\n",
    "        units = 5,\n",
    "        activation = out_activation\n",
    "    )(dropout_2)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5gVil62UWxY"
   },
   "source": [
    "# HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "468PKXK2UfW9"
   },
   "source": [
    "## RNN ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3VJ7dSFUWFg"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    input_shape=(324,),\n",
    "    input_length=314,\n",
    "    embedding_matrix=glove_emb_300d,\n",
    "    epochs=3)\n",
    "\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "param_grid = dict(model__gru_activation=activation_functions)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O5PdXKvUiJQ"
   },
   "source": [
    "## NN ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQYacuEWUcYE"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh',\n",
    "    epochs=3)\n",
    "\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "param_grid = dict(model__hid_activation=activation_functions)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kTGw_psUkgG"
   },
   "source": [
    "RNN UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uko_7JhXUnH7"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh',\n",
    "    epochs=2)\n",
    "\n",
    "gru_1_units = [16, 32]\n",
    "gru_2_units = [16, 32]\n",
    "param_grid = dict(model__gru_1_units = gru_1_units,\n",
    "                  model__gru_2_units = gru_2_units)\n",
    "\n",
    "GS = GridSearchCV(estimator = model,param_grid = param_grid,\n",
    "    scoring = 'accuracy',n_jobs=-1,cv = 2,verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLCQZvbXUoyu"
   },
   "source": [
    "## NN UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySMOYw1wUqYB"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=32, gru_2_units=32,\n",
    "    epochs=2)\n",
    "\n",
    "\n",
    "hid_1_units = [32, 64]\n",
    "hid_2_units = [32, 64]\n",
    "param_grid = dict(model__hid_1_units = hid_1_units,\n",
    "                  model__hid_2_units = hid_2_units)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWFHGI9qUs5A"
   },
   "source": [
    "## LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwMkrfBVUvYJ"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=32, gru_2_units=32, hid_1_units=64, hid_2_units=32,\n",
    "    epochs=3)\n",
    "\n",
    "lr = [10**-3, 10**-2, 10**-1]\n",
    "param_grid = dict(model__learning_rate= lr)\n",
    "\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVrrn6mZUw3x"
   },
   "source": [
    "## DROPOUT RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WS7tmQc5Uzwt"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=32, gru_2_units=32, hid_1_units=64, hid_2_units=32,\n",
    "    learning_rate=10**-2,\n",
    "    epochs=3)\n",
    "\n",
    "dropout_rates = [0.0, 0.1 ,0.2]\n",
    "param_grid = dict(model__dropout_rate=dropout_rates)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PYZvJaMU0vH"
   },
   "source": [
    "## KERNEL REGULARIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkbM_Zy-U4yh"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=32, gru_2_units=32, hid_1_units=64, hid_2_units=32,\n",
    "    learning_rate=10**-2, dropout_rate=0.2,\n",
    "    epochs=3)\n",
    "\n",
    "kernel_regularizer = [None, 'l1', 'l2', 'l1_l2']\n",
    "param_grid = dict(model__kernel_regularizer=kernel_regularizer)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auC6fDAKU7Qs"
   },
   "source": [
    "## KERNEL INITIALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UC-eTZmU9NS"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=32, gru_2_units=32, hid_1_units=64, hid_2_units=32,\n",
    "    learning_rate=10**-2, dropout_rate=0.2, kernel_regularizer=None,\n",
    "    epochs=3)\n",
    "\n",
    "kernel_initializers = ['glorot_uniform', 'he_normal']\n",
    "param_grid = dict(model__kernel_initializer=kernel_initializers)\n",
    "\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0QzNr6OU-Wr"
   },
   "source": [
    "## OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiMImJAJVA26"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='relu', gru_1_units=32, gru_2_units=32, hid_1_units=64, hid_2_units=32,\n",
    "    learning_rate=10**-2, dropout_rate=0.2, kernel_regularizer=None, kernel_initializer='glorot_uniform',\n",
    "    epochs=3)\n",
    "\n",
    "optimizers = ['adam', 'sgd']\n",
    "param_grid = dict(model__optimizer=optimizers)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CggZoiqVDSH"
   },
   "source": [
    "## BATCH SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHAIxXUIVEXW"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model, input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=32, gru_2_units=32, hid_1_units=64, hid_2_units=32,\n",
    "    learning_rate=10**-2, dropout_rate=0.2, kernel_regularizer=None, kernel_initializer='glorot_uniform',\n",
    "    optimizer='adam',\n",
    "    epochs=2)\n",
    "\n",
    "batch_size = [64, None, 16, 32]\n",
    "param_grid = dict(batch_size=batch_size)\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = model, param_grid = param_grid, scoring = 'accuracy',\n",
    "    n_jobs=-1, cv = 2, verbose=1)\n",
    "\n",
    "grid_result = GS.fit(X_train, y_train)\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aG8wBguVFZQ"
   },
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFNEOBVFVIUH"
   },
   "outputs": [],
   "source": [
    "GLOVE_model = create_model(\n",
    "    input_shape=(324,), input_length=314, embedding_matrix=glove_emb_300d,\n",
    "    gru_activation='tanh', hid_activation='relu', gru_1_units=16, gru_2_units=16, hid_1_units=32, hid_2_units=32,\n",
    "    learning_rate=10**-3, dropout_rate=0.2, kernel_regularizer='l2', kernel_initializer='glorot_uniform',\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "GLOVE_history = GLOVE_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qpSyl42VLeY"
   },
   "outputs": [],
   "source": [
    "TF_IDF_model = create_model(\n",
    "    input_shape=(324,), input_length=314, embedding_matrix=dense_tfidf_matrix_with_zeros.T,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=16, gru_2_units=16, hid_1_units=32, hid_2_units=32,\n",
    "    learning_rate=10**-3, dropout_rate=0.2, kernel_regularizer='l2', kernel_initializer='glorot_uniform',\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "TF_IDF_history = TF_IDF_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g_Tz-i1zJZo"
   },
   "outputs": [],
   "source": [
    "PPMI_model = create_model(\n",
    "    input_shape=(324,), input_length=314, embedding_matrix=ppmi_matrix,\n",
    "    gru_activation='tanh', hid_activation='tanh', gru_1_units=16, gru_2_units=16, hid_1_units=32, hid_2_units=32,\n",
    "    learning_rate=10**-3, dropout_rate=0.2, kernel_regularizer='l2', kernel_initializer='glorot_uniform',\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "PPMI_history = PPMI_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFxcyo6o1QpU"
   },
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNe_R5Pw3f7r"
   },
   "outputs": [],
   "source": [
    "# model predictions\n",
    "glove_y_pred = GLOVE_model.predict(X_test)\n",
    "tf_idf_y_pred = TF_IDF_model.predict(X_test)\n",
    "ppmi_y_pred = PPMI_model.predict(X_test)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "glove_loss, glove_accuracy = GLOVE_model.evaluate(X_test, y_test)\n",
    "tf_idf_loss, tf_idf_accuracy = TF_IDF_model.evaluate(X_test, y_test)\n",
    "ppmi_loss, ppmi_accuracy = PPMI_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBfK7IqyvF_s"
   },
   "outputs": [],
   "source": [
    "# Extract training history\n",
    "glove_training_accuracy = GLOVE_history.history['accuracy']\n",
    "glove_validation_accuracy = GLOVE_history.history['val_accuracy']\n",
    "\n",
    "tf_idf_training_accuracy = TF_IDF_history.history['accuracy']\n",
    "tf_idf_validation_accuracy = TF_IDF_history.history['val_accuracy']\n",
    "\n",
    "ppmi_training_accuracy = PPMI_history.history['accuracy']\n",
    "ppmi_validation_accuracy = PPMI_history.history['val_accuracy']\n",
    "\n",
    "\n",
    "# Example data\n",
    "epochs = range(1, len(glove_validation_accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training and validation accuracy for GLOVE model\n",
    "plt.plot(epochs, glove_training_accuracy, linestyle='-', linewidth=2, label='GLOVE Train Acc', color='green')\n",
    "plt.plot(epochs, glove_validation_accuracy, linestyle='--', linewidth=2, label='GLOVE Val Acc', color='green')\n",
    "\n",
    "# Plot training and validation accuracy for PPMI model\n",
    "plt.plot(epochs, ppmi_training_accuracy, linestyle='-', linewidth=2, label='PPMI Train Acc', color='red')\n",
    "plt.plot(epochs, ppmi_validation_accuracy, linestyle='--', linewidth=2, label='PPMI Val Acc', color='red')\n",
    "\n",
    "# Plot training and validation accuracy for TF-IDF model\n",
    "plt.plot(epochs, tf_idf_training_accuracy, linestyle='-', linewidth=2, label='TF-IDF Train Acc', color='purple')\n",
    "plt.plot(epochs, tf_idf_validation_accuracy, linestyle='--', linewidth=2, label='TF-IDF Val Acc', color='purple')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps9aGCeFvyzW"
   },
   "outputs": [],
   "source": [
    "model_names = ['GloVe', 'TF-IDF', 'PPMI']\n",
    "loss_values = [glove_loss, tf_idf_loss, ppmi_loss]\n",
    "accuracy_values = [glove_accuracy, tf_idf_accuracy, ppmi_accuracy]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(model_names, loss_values, color='skyblue')\n",
    "plt.title('Loss on Test Data')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(model_names, accuracy_values, color='lightgreen')\n",
    "plt.title('Accuracy on Test Data')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HzJfpW7wFDr"
   },
   "outputs": [],
   "source": [
    "y_true_indices = np.argmax(y_test, axis=1)\n",
    "y_pred_indices = np.argmax(glove_y_pred, axis=1)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "\n",
    "class_labels = ['A', 'B1', 'B2', 'C1', 'C2']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix GloVe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYWoDwBTAJB2"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpgqtwdLDF54"
   },
   "outputs": [],
   "source": [
    "X = np.array(CORPUS)\n",
    "y = label_encoder.fit_transform(CEFR_OVERALL)\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3e1jDiIAAhi"
   },
   "outputs": [],
   "source": [
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jBwcoI-ADMg"
   },
   "outputs": [],
   "source": [
    "bert_perprocess_model = hub.KerasLayer(preprocess_url, name='preprocessing')\n",
    "bert_model = hub.KerasLayer(encoder_url, name='BERT_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_bqleD9ARmy"
   },
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_perprocess_model(text_input)\n",
    "bert_output = bert_model(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNMp6aBKA279"
   },
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Dropout(0.2, name='dropout')(bert_output)\n",
    "output_layer = tf.keras.layers.Dense(5, activation='softmax', name = 'output')(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_aZZPJhVfjG"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[text_input], outputs=[output_layer])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=0.008,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egvlS9R6y_kb"
   },
   "source": [
    "# BERT EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMuoyBelGjAF"
   },
   "outputs": [],
   "source": [
    "bert_loss, bert_accuracy = model.evaluate(X_test, y_test)\n",
    "bert_y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XpI5Bm-zCgZ"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.bar('BERT - Loss', bert_loss, color='blue', alpha=0.6, label='Loss')\n",
    "ax.bar('BERT - Accuracy', bert_accuracy, color='green', alpha=0.6, label='Accuracy')\n",
    "ax.set_ylabel('Loss / Accuracy Value')\n",
    "\n",
    "ax.set_title('Loss and Accuracy for BERT')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fOFthmpHwco"
   },
   "outputs": [],
   "source": [
    "y_true_indices = y_test\n",
    "y_pred_indices = np.argmax(bert_y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "\n",
    "class_labels = ['A', 'B1', 'B2', 'C1', 'C2']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIZ6Rt9Wz6Y8"
   },
   "outputs": [],
   "source": [
    "VALENTINA BITETTO 508285, ANA SUAREZ 503162, ANDREA LOLLI 503035"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
